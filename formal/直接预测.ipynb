{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34886007",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-18 22:22:00,505\tWARNING services.py:1994 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 6709796864 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=10.24gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import time\n",
    "import math\n",
    "import datetime\n",
    "from math import log, floor\n",
    "from sklearn.neighbors import KDTree\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "#import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import colors\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import multiprocessing\n",
    "from functools import partial\n",
    "import ray\n",
    "ray.init()\n",
    "\n",
    "import modin.pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfcd825",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('wtbdata_245days.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d3a4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[(data['Patv'].notnull()) & (data['Day']>160)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb1d684",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lag_n = 288*7\n",
    "lag_n = 288"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a0d637",
   "metadata": {},
   "outputs": [],
   "source": [
    "turbid = data['TurbID'].unique()\n",
    "num_processes = 20\n",
    "\n",
    "part_num = int(len(turbid)/num_processes+0.5)\n",
    "\n",
    "df_split = []\n",
    "temp_id_group = []\n",
    "count = 0\n",
    "for i in turbid:\n",
    "    temp_id_group.append(i)\n",
    "    if count%part_num==1:\n",
    "        df_split.append(temp_id_group)\n",
    "        temp_id_group = []\n",
    "    count += 1\n",
    "df_split.append(temp_id_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "674ddc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "turbid = data['TurbID'].unique()\n",
    "num_processes = 20\n",
    "\n",
    "part_num = int(len(turbid)/num_processes+0.5)\n",
    "\n",
    "df_split = []\n",
    "temp_id_group = []\n",
    "count = 0\n",
    "for i in turbid:\n",
    "    temp_id_group.append(i)\n",
    "    if count%part_num==1:\n",
    "        df_split.append(data[data['TurbID'].isin(temp_id_group)])\n",
    "        temp_id_group = []\n",
    "    count += 1\n",
    "df_split.append(data[data['TurbID'].isin(temp_id_group)])\n",
    "\n",
    "\n",
    "def lag_feature(data, feat_columns, li):    \n",
    "    # 在对应的位置设置lag列\n",
    "    for shift_num in li:\n",
    "        start = time.time()\n",
    "        temp_data = data.groupby(['TurbID'])[feat_columns].shift(shift_num)\n",
    "        end1 = time.time()\n",
    "        temp_data.columns=[i+\"_lag_\"+str(shift_num) for i in feat_columns]\n",
    "        data = pd.concat([data,temp_data],axis=1)\n",
    "        end2 = time.time()\n",
    "        print('groupby time:', end1-start)\n",
    "        print('concat time: ', end2-end1)\n",
    "    return data \n",
    "\n",
    "def parallelize_df(df_split, func, num_processes=20):\n",
    "    with multiprocessing.Pool(num_processes) as p:\n",
    "        df = pd.concat(p.map(func, df_split))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b66eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_columns = ['Wspd','Prtv','Patv']\n",
    "li = [i for i in range(288,288+lag_n)]\n",
    "prod = partial(lag_feature, feat_columns=feat_columns, li=li)\n",
    "data_lag1 = parallelize_df(df_split, prod, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3c7544",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lag1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d07b08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lag1['hour'] = data_lag1['Tmstamp'].apply(lambda x:int(x.split(':')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736291e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_feat = list(['TurbID']+list(data_lag1.columns[13:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4ae91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = data_lag1[data_lag1['Day'].isin([243,242])]\n",
    "test_data = data_lag1[data_lag1['Day'].isin([244,245])]\n",
    "train_data = data_lag1[data_lag1['Day']<242]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ce495f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gbm = LGBMRegressor(objective='regression',\n",
    "                        num_leaves=128, \n",
    "                        learning_rate=0.07, \n",
    "                        n_estimators=1000,\n",
    "                        max_depth=7)\n",
    "gbm.fit(train_data[use_feat], train_data['Patv'], \n",
    "        eval_set=[(val_data[use_feat], val_data['Patv'])], \n",
    "        eval_metric='rmse', early_stopping_rounds=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a78536a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = gbm.predict(test_data[use_feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d172689",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['predict'] = predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda1421b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[test_data['TurbID']==1][['Patv','predict']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb50f3c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
